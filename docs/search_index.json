[
["index.html", "Data Analytics in RStudio Preface", " Data Analytics in RStudio Gaurav Satav 2018-02-22 Preface This document is an attempt to provide the reader with a walkthrough into how a typical analysis is carried out using R Studios. "],
["introduction.html", "Chapter 1 Introduction 1.1 The R Language 1.2 R Studios", " Chapter 1 Introduction Organisations collect data that they have gathered from customers, businesses, economy and practical experience. Data is then processed after gathering and is categorised as per the requirement and analysis is done to study purchase patterns and etc. It has always been important to know ones customer and have an understanding of the market one is operating in, but it has only been in recent years that we’ve experience a tremendous acceleration in the rate of data generation. The idea is to make sense of the data you have, to analyse it and share better business prospects in the near future and how you’re going to do it, is with the concepts of analytics. It is the science of extracting trends, patterns and useful information from a set of existing data which will be of no use if not analysed. It is a kind of business intelligence that is now used for gaining profits and making better use of resources. This can also help in improving managerial operations and leverage organisations to next level. If not analysed this data is going to get wasted whereas if analysed properly this data can help us in finding information that is powerful to bring in a change in the patterns of how business is already working or going. 1.1 The R Language R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows and MacOS. The R environment R is an integrated suite of software facilities for data manipulation, calculation and graphical display. Among other things it has an effective data handling and storage facility, a suite of operators for calculations on arrays, in particular matrices, a large, coherent, integrated collection of intermediate tools for data analysis, graphical facilities for data analysis and display either directly at the computer or on hardcopy, and a well developed, simple and effective programming language (called ‘S’) which includes conditionals, loops, user defined recursive functions and input and output facilities. (Indeed most of the system supplied functions are themselves written in the S language.) The term “environment” is intended to characterize it as a fully planned and coherent system, rather than an incremental accretion of very specific and inflexible tools, as is frequently the case with other data analysis software. R is very much a vehicle for newly developing methods of interactive data analysis. It has developed rapidly, and has been extended by a large collection of packages. However, most programs written in R are essentially ephemeral, written for a single piece of data analysis. You can get yourself aquainted with the basics of R by visiting this link You can download R by clicking the link here. 1.2 R Studios RStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management. RStudio is available in open source and commercial editions and runs on the desktop (Windows, Mac, and Linux) or in a browser connected to RStudio Server or RStudio Server Pro (Debian/Ubuntu, RedHat/CentOS, and SUSE Linux). Downloading R Studios Before downloading R Studios make sure you have R installed on your system. If not the refer the previous page for the link Basically there are two version of RStudio ( whats the difference? ) Desktop Version Server Version We recommend installation of the server version or R Studio and once its installed we can access it using our browser at port 8787 Click here to install R Studio for linux. "],
["setting-up-a-project.html", "Chapter 2 Setting up a Project 2.1 Github Integration", " Chapter 2 Setting up a Project Before we start with our analysis, we’ll start off by setting up a project. Setting up a project helps us in the following ways Keeping track of all the files and variables which are created in between our executions. It also helps us to reproduce our work and keep a track of all the libraries upon which our code relies upon (see packrat). It allows us to enable version control. 2.1 Github Integration Version control helps software teams manage changes to source code over time. Version control software keeps track of every modification to the code in a special kind of database. If a mistake is made, developers can turn back the clock and compare earlier versions of the code to help fix the mistake while minimizing disruption to all team members. Version control systems have been around for a long time but continue to increase in popularity with data science workflows. The RStudio IDE has integrated support for version control which would help us keep track of our changes and push them onto Github. Additional Resource - Using Version Control with RStudio "],
["preparing-the-canvas.html", "Chapter 3 Preparing the Canvas 3.1 R Markdown 3.2 Dashboards 3.3 Blog 3.4 Books 3.5 Web Applications.", " Chapter 3 Preparing the Canvas Consider the following scenario, you are asked to perform analysis on some data, we would all agree that it would be a tedious task to complete our analysis using the command line interface. The RStudio IDE (or any IDE for that matter) provides us with the freedom to reproduce the execution of our code sequentially to be executed on someone else along with host of other important advantage. Now as it happens at the end of most analysis we are required to produce a report to be shared. This report in general takes one of the following forms. A Spreadsheet. A text document. A powerpoint presentation. thinking on similar lines as we did while comparing the CMD line to a text editor we see that it would really be a tedious job to produce reports especially if the reports are going to be repetative and similar in nature.Before we start writing a single line of code, I encourage you to ask yourself, what is my output file format going to be ?. Beginning at the end. R Studio provides us with the following (along with many other) output formats in which we can share our analysis. R Markdown Dashboards Web Pages (Blogs and Books) Web Applications We’ll skim on the surface of each of these output formats in the following chapters. 3.1 R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com. When you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 3.1.0.1 Including Plots You can also embed plots, for example: Note that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot. 3.2 Dashboards Dashboards are a great tool to represent live data or data in forms of reports. The flexdashboard library allows us to do just that. It enables you to easily create flexible, attractive, interactive dashboards with R. Authoring and customization of dashboards is done using R Markdown and you can optionally include Shiny(more on it later) components for additional interactivity. Highlights of the flexdashboard package include: Support for a wide variety of components including interactive htmlwidgets; base, lattice, and grid graphics; tabular data; gauges; and value boxes. Flexible and easy to specify row and column-based layouts. Components are intelligently re-sized to fill the browser and adapted for display on mobile devices. Extensive support for text annotations to include assumptions, contextual narrative, and analysis within dashboards. Storyboard layouts for presenting sequences of visualizations and related commentary. By default dashboards are standard HTML documents that can be deployed on any web server or even attached to an email message. You can optionally add Shiny components for additional interactivity and then deploy on Shiny Server or shinyapps.io. You can explore the gallery of the dashboards at https://rmarkdown.rstudio.com/flexdashboard/examples.html Additional learning resource is here 3.3 Blog It so often happens that we continue to learn new things and and more often than not, forget them due to one reason or the other. Maintaining a blog helps us to write in our own words what it is that we’ve learned and also it can help you showcase your knowledge to someone when asked upon. Blogdown is an awesome tool developed by Yihui Xi which makes our lives a whole lot easier to create, maintain and update our own blog. Its a bit of a trouble at start, but once you get going you come to see its effectiveness. Once we create our blog we can then choose to host it either on Github Pages or on Netlify. Additional Resources blogdown: Creating Websites with R Markdown Building a blog with blogdown 3.4 Books Similar to the blogdown package, bookdown as the name suggest is used for writing books. The book you’re currently reading was written using the same package. Additional Resources - bookdown: Authoring Books and Technical Documents with R Markdown 3.5 Web Applications. Shiny is an R package that makes it easy to build interactive web applications (apps) straight from R. A simple example of the application is seen here This application is hosted on the https://www.shinyapps.io/ server . Additional Resources Learn Shiny "],
["getting-to-work.html", "Chapter 4 Getting to work 4.1 Once upon a time… 4.2 Load and check data 4.3 Feature Engineering 4.4 Missingness 4.5 Prediction", " Chapter 4 Getting to work There is a problem hosted on Kaggle (a platform which hosts many predictive modelling and analytics competitions) knows as the Titanic: Machine Learning from Disaster. In this competitions, we are asked to predict whether a given set passenger survived or died in the sinking of RMS Titanic. We’ll now start our walkthrough. All credits for the 4.1 Once upon a time… The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships. One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class. 4.2 Load and check data # Load packages # Base Package library(&#39;base&#39;) # Visualization library(&#39;ggplot2&#39;) library(&#39;ggthemes&#39;) library(&#39;scales&#39;) # Data Manipulation library(&#39;dplyr&#39;) # Imputation library(&#39;mice&#39;) # Classification algorithm library(&#39;randomForest&#39;) Now that our packages are loaded, let’s read in and take a peek at the data. train &lt;- read.csv(&#39;./input/train.csv&#39;, stringsAsFactors = F) test &lt;- read.csv(&#39;./input/test.csv&#39;, stringsAsFactors = F) full &lt;- bind_rows(train, test) # bind training &amp; test data # check data str(full) ## &#39;data.frame&#39;: 1309 obs. of 12 variables: ## $ PassengerId: int 1 2 3 4 5 6 7 8 9 10 ... ## $ Survived : int 0 1 1 1 0 0 0 0 1 1 ... ## $ Pclass : int 3 1 3 1 3 3 1 3 3 2 ... ## $ Name : chr &quot;Braund, Mr. Owen Harris&quot; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot; &quot;Heikkinen, Miss. Laina&quot; &quot;Futrelle, Mrs. Jacques Heath (Lily May Peel)&quot; ... ## $ Sex : chr &quot;male&quot; &quot;female&quot; &quot;female&quot; &quot;female&quot; ... ## $ Age : num 22 38 26 35 35 NA 54 2 27 14 ... ## $ SibSp : int 1 1 0 1 0 0 0 3 0 1 ... ## $ Parch : int 0 0 0 0 0 0 0 1 2 0 ... ## $ Ticket : chr &quot;A/5 21171&quot; &quot;PC 17599&quot; &quot;STON/O2. 3101282&quot; &quot;113803&quot; ... ## $ Fare : num 7.25 71.28 7.92 53.1 8.05 ... ## $ Cabin : chr &quot;&quot; &quot;C85&quot; &quot;&quot; &quot;C123&quot; ... ## $ Embarked : chr &quot;S&quot; &quot;C&quot; &quot;S&quot; &quot;S&quot; ... We’ve got a sense of our variables, their class type, and the first few observations of each. We know we’re working with 1309 observations of 12 variables. To make things a bit more explicit since a couple of the variable names aren’t 100% illuminating, here’s what we’ve got to deal with: 4.3 Feature Engineering 4.3.1 What’s in a name? The first variable which catches my attention is passenger name because we can break it down into additional meaningful variables which can feed predictions or be used in the creation of additional new variables. For instance, passenger title is contained within the passenger name variable and we can use surname to represent families. Let’s do some feature engineering! # Grab title from passenger names full$Title &lt;- gsub(&#39;(.*, )|(\\\\..*)&#39;, &#39;&#39;, full$Name) # Show title counts by sex table(full$Sex, full$Title) ## ## Capt Col Don Dona Dr Jonkheer Lady Major Master Miss Mlle Mme ## female 0 0 0 1 1 0 1 0 0 260 2 1 ## male 1 4 1 0 7 1 0 2 61 0 0 0 ## ## Mr Mrs Ms Rev Sir the Countess ## female 0 197 2 0 0 1 ## male 757 0 0 8 1 0 # Titles with very low cell counts to be combined to &quot;rare&quot; level rare_title &lt;- c(&#39;Dona&#39;, &#39;Lady&#39;, &#39;the Countess&#39;,&#39;Capt&#39;, &#39;Col&#39;, &#39;Don&#39;, &#39;Dr&#39;, &#39;Major&#39;, &#39;Rev&#39;, &#39;Sir&#39;, &#39;Jonkheer&#39;) # Also reassign mlle, ms, and mme accordingly full$Title[full$Title == &#39;Mlle&#39;] &lt;- &#39;Miss&#39; full$Title[full$Title == &#39;Ms&#39;] &lt;- &#39;Miss&#39; full$Title[full$Title == &#39;Mme&#39;] &lt;- &#39;Mrs&#39; full$Title[full$Title %in% rare_title] &lt;- &#39;Rare Title&#39; # Show title counts by sex again table(full$Sex, full$Title) ## ## Master Miss Mr Mrs Rare Title ## female 0 264 0 198 4 ## male 61 0 757 0 25 # Finally, grab surname from passenger name full$Surname &lt;- sapply(full$Name, function(x) strsplit(x, split = &#39;[,.]&#39;)[[1]][1]) We have 875 unique surnames. I would be interested to infer ethnicity based on surname — another time. 4.3.2 Do families sink or swim together? Now that we’ve taken care of splitting passenger name into some new variables, we can take it a step further and make some new family variables. First we’re going to make a family size variable based on number of siblings/spouse(s) (maybe someone has more than one spouse?) and number of children/parents. # Create a family size variable including the passenger themselves full$Fsize &lt;- full$SibSp + full$Parch + 1 # Create a family variable full$Family &lt;- paste(full$Surname, full$Fsize, sep=&#39;_&#39;) What does our family size variable look like? To help us understand how it may relate to survival, let’s plot it among the training data. # Use ggplot2 to visualize the relationship between family size &amp; survival ggplot(full[1:891,], aes(x = Fsize, fill = factor(Survived))) + geom_bar(stat=&#39;count&#39;, position=&#39;dodge&#39;) + scale_x_continuous(breaks=c(1:11)) + labs(x = &#39;Family Size&#39;) + theme_few() Ah hah. We can see that there’s a survival penalty to singletons and those with family sizes above 4. We can collapse this variable into three levels which will be helpful since there are comparatively fewer large families. Let’s create a discretized family size variable. # Discretize family size full$FsizeD[full$Fsize == 1] &lt;- &#39;singleton&#39; full$FsizeD[full$Fsize &lt; 5 &amp; full$Fsize &gt; 1] &lt;- &#39;small&#39; full$FsizeD[full$Fsize &gt; 4] &lt;- &#39;large&#39; # Show family size by survival using a mosaic plot mosaicplot(table(full$FsizeD, full$Survived), main=&#39;Family Size by Survival&#39;, shade=TRUE) The mosaic plot shows that we preserve our rule that there’s a survival penalty among singletons and large families, but a benefit for passengers in small families. I want to do something further with our age variable, but 263 rows have missing age values, so we will have to wait until after we address missingness. 4.3.3 Treat a few more variables … What’s left? There’s probably some potentially useful information in the passenger cabin variable including about their deck. Let’s take a look. # This variable appears to have a lot of missing values full$Cabin[1:28] ## [1] &quot;&quot; &quot;C85&quot; &quot;&quot; &quot;C123&quot; &quot;&quot; ## [6] &quot;&quot; &quot;E46&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [11] &quot;G6&quot; &quot;C103&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [16] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [21] &quot;&quot; &quot;D56&quot; &quot;&quot; &quot;A6&quot; &quot;&quot; ## [26] &quot;&quot; &quot;&quot; &quot;C23 C25 C27&quot; # The first character is the deck. For example: strsplit(full$Cabin[2], NULL)[[1]] ## [1] &quot;C&quot; &quot;8&quot; &quot;5&quot; # Create a Deck variable. Get passenger deck A - F: full$Deck&lt;-factor(sapply(full$Cabin, function(x) strsplit(x, NULL)[[1]][1])) There’s more that likely could be done here including looking into cabins with multiple rooms listed (e.g., row 28: “C23 C25 C27”), but given the sparseness of the column we’ll stop here. 4.4 Missingness Now we’re ready to start exploring missing data and rectifying it through imputation. There are a number of different ways we could go about doing this. Given the small size of the dataset, we probably should not opt for deleting either entire observations (rows) or variables (columns) containing missing values. We’re left with the option of either replacing missing values with a sensible values given the distribution of the data, e.g., the mean, median or mode. Finally, we could go with prediction. We’ll use both of the two latter methods and I’ll rely on some data visualization to guide our decisions. 4.4.1 Sensible value imputation # Passengers 62 and 830 are missing Embarkment full[c(62, 830), &#39;Embarked&#39;] ## [1] &quot;&quot; &quot;&quot; ## We will infer their values for **embarkment** based on present data that we can imagine may be relevant: **passenger class** and **fare**. We see that they paid&lt;b&gt; $ 80 &lt;/b&gt;and&lt;b&gt; $ NA &lt;/b&gt;respectively and their classes are&lt;b&gt; 1 &lt;/b&gt;and&lt;b&gt; NA &lt;/b&gt;. So from where did they embark? # Get rid of our missing passenger IDs embark_fare &lt;- full %&gt;% filter(PassengerId != 62 &amp; PassengerId != 830) # Use ggplot2 to visualize embarkment, passenger class, &amp; median fare ggplot(embark_fare, aes(x = Embarked, y = Fare, fill = factor(Pclass))) + geom_boxplot() + geom_hline(aes(yintercept=80), colour=&#39;red&#39;, linetype=&#39;dashed&#39;, lwd=2) + scale_y_continuous(labels=dollar_format()) + theme_few() Voilà! The median fare for a first class passenger departing from Charbourg (‘C’) coincides nicely with the $80 paid by our embarkment-deficient passengers. I think we can safely replace the NA values with ‘C’. # Since their fare was $80 for 1st class, they most likely embarked from &#39;C&#39; full$Embarked[c(62, 830)] &lt;- &#39;C&#39; We’re close to fixing the handful of NA values here and there. Passenger on row 1044 has an NA Fare value. # Show row 1044 full[1044, ] ## PassengerId Survived Pclass Name Sex Age SibSp Parch ## 1044 1044 NA 3 Storey, Mr. Thomas male 60.5 0 0 ## Ticket Fare Cabin Embarked Title Surname Fsize Family FsizeD ## 1044 3701 NA S Mr Storey 1 Storey_1 singleton ## Deck ## 1044 &lt;NA&gt; This is a third class passenger who departed from Southampton (‘S’). Let’s visualize Fares among all others sharing their class and embarkment (n = 494). ggplot(full[full$Pclass == &#39;3&#39; &amp; full$Embarked == &#39;S&#39;, ], aes(x = Fare)) + geom_density(fill = &#39;#99d6ff&#39;, alpha=0.4) + geom_vline(aes(xintercept=median(Fare, na.rm=T)), colour=&#39;red&#39;, linetype=&#39;dashed&#39;, lwd=1) + scale_x_continuous(labels=dollar_format()) + theme_few() From this visualization, it seems quite reasonable to replace the NA Fare value with median for their class and embarkment which is $8.05. # Replace missing fare value with median fare for class/embarkment full$Fare[1044] &lt;- median(full[full$Pclass == &#39;3&#39; &amp; full$Embarked == &#39;S&#39;, ]$Fare, na.rm = TRUE) 4.4.2 Predictive imputation Finally, as we noted earlier, there are quite a few missing Age values in our data. We are going to get a bit more fancy in imputing missing age values. Why? Because we can. We will create a model predicting ages based on other variables. # Show number of missing Age values sum(is.na(full$Age)) ## [1] 263 We could definitely use rpart (recursive partitioning for regression) to predict missing ages, but I’m going to use the mice package for this task just for something different. You can read more about multiple imputation using chained equations in r here (PDF). Since we haven’t done it yet, I’ll first factorize the factor variables and then perform mice imputation. # Make variables factors into factors factor_vars &lt;- c(&#39;PassengerId&#39;,&#39;Pclass&#39;,&#39;Sex&#39;,&#39;Embarked&#39;, &#39;Title&#39;,&#39;Surname&#39;,&#39;Family&#39;,&#39;FsizeD&#39;) full[factor_vars] &lt;- lapply(full[factor_vars], function(x) as.factor(x)) # Set a random seed set.seed(129) # Perform mice imputation, excluding certain less-than-useful variables: mice_mod &lt;- mice(full[, !names(full) %in% c(&#39;PassengerId&#39;,&#39;Name&#39;,&#39;Ticket&#39;,&#39;Cabin&#39;,&#39;Family&#39;,&#39;Surname&#39;,&#39;Survived&#39;)], method=&#39;rf&#39;) ## ## iter imp variable ## 1 1 Age Deck ## 1 2 Age Deck ## 1 3 Age Deck ## 1 4 Age Deck ## 1 5 Age Deck ## 2 1 Age Deck ## 2 2 Age Deck ## 2 3 Age Deck ## 2 4 Age Deck ## 2 5 Age Deck ## 3 1 Age Deck ## 3 2 Age Deck ## 3 3 Age Deck ## 3 4 Age Deck ## 3 5 Age Deck ## 4 1 Age Deck ## 4 2 Age Deck ## 4 3 Age Deck ## 4 4 Age Deck ## 4 5 Age Deck ## 5 1 Age Deck ## 5 2 Age Deck ## 5 3 Age Deck ## 5 4 Age Deck ## 5 5 Age Deck # Save the complete output mice_output &lt;- complete(mice_mod) Let’s compare the results we get with the original distribution of passenger ages to ensure that nothing has gone completely awry. # Plot age distributions par(mfrow=c(1,2)) hist(full$Age, freq=F, main=&#39;Age: Original Data&#39;, col=&#39;darkgreen&#39;, ylim=c(0,0.04)) hist(mice_output$Age, freq=F, main=&#39;Age: MICE Output&#39;, col=&#39;lightgreen&#39;, ylim=c(0,0.04)) Things look good, so let’s replace our age vector in the original data with the output from the mice model. # Replace Age variable from the mice model. full$Age &lt;- mice_output$Age # Show new number of missing Age values sum(is.na(full$Age)) ## [1] 0 We’ve finished imputing values for all variables that we care about for now! Now that we have a complete Age variable, there are just a few finishing touches I’d like to make. We can use Age to do just a bit more feature engineering … 4.4.3 Feature Engineering: Round 2 Now that we know everyone’s age, we can create a couple of new age-dependent variables: Child and Mother. A child will simply be someone under 18 years of age and a mother is a passenger who is 1) female, 2) is over 18, 3) has more than 0 children (no kidding!), and 4) does not have the title ‘Miss’. # First we&#39;ll look at the relationship between age &amp; survival ggplot(full[1:891,], aes(Age, fill = factor(Survived))) + geom_histogram() + # I include Sex since we know (a priori) it&#39;s a significant predictor facet_grid(.~Sex) + theme_few() # Create the column child, and indicate whether child or adult full$Child[full$Age &lt; 18] &lt;- &#39;Child&#39; full$Child[full$Age &gt;= 18] &lt;- &#39;Adult&#39; # Show counts table(full$Child, full$Survived) ## ## 0 1 ## Adult 484 274 ## Child 65 68 Looks like being a child doesn’t hurt, but it’s not going to necessarily save you either! We will finish off our feature engineering by creating the Mother variable. Maybe we can hope that mothers are more likely to have survived on the Titanic. # Adding Mother variable full$Mother &lt;- &#39;Not Mother&#39; full$Mother[full$Sex == &#39;female&#39; &amp; full$Parch &gt; 0 &amp; full$Age &gt; 18 &amp; full$Title != &#39;Miss&#39;] &lt;- &#39;Mother&#39; # Show counts table(full$Mother, full$Survived) ## ## 0 1 ## Mother 16 39 ## Not Mother 533 303 # Finish by factorizing our two new factor variables full$Child &lt;- factor(full$Child) full$Mother &lt;- factor(full$Mother) All of the variables we care about should be taken care of and there should be no missing data. I’m going to double check just to be sure: md.pattern(full) ## Warning in data.matrix(x): NAs introduced by coercion ## Warning in data.matrix(x): NAs introduced by coercion ## Warning in data.matrix(x): NAs introduced by coercion ## PassengerId Pclass Sex Age SibSp Parch Fare Embarked Title Surname ## 150 1 1 1 1 1 1 1 1 1 1 ## 61 1 1 1 1 1 1 1 1 1 1 ## 54 1 1 1 1 1 1 1 1 1 1 ## 511 1 1 1 1 1 1 1 1 1 1 ## 30 1 1 1 1 1 1 1 1 1 1 ## 235 1 1 1 1 1 1 1 1 1 1 ## 176 1 1 1 1 1 1 1 1 1 1 ## 92 1 1 1 1 1 1 1 1 1 1 ## 0 0 0 0 0 0 0 0 0 0 ## Fsize Family FsizeD Child Mother Ticket Survived Deck Name Cabin ## 150 1 1 1 1 1 1 1 1 0 0 2 ## 61 1 1 1 1 1 1 0 1 0 0 3 ## 54 1 1 1 1 1 0 1 1 0 0 3 ## 511 1 1 1 1 1 1 1 0 0 0 3 ## 30 1 1 1 1 1 0 0 1 0 0 4 ## 235 1 1 1 1 1 1 0 0 0 0 4 ## 176 1 1 1 1 1 0 1 0 0 0 4 ## 92 1 1 1 1 1 0 0 0 0 0 5 ## 0 0 0 0 0 352 418 1014 1309 1309 4402 Wow! We have finally finished treating all of the relevant missing values in the Titanic dataset which has included some fancy imputation with mice. We have also successfully created several new variables which we hope will help us build a model which reliably predicts survival. 4.5 Prediction At last we’re ready to predict who survives among passengers of the Titanic based on variables that we carefully curated and treated for missing values. For this, we will rely on the randomForest classification algorithm; we spent all that time on imputation, after all. 4.5.1 Split into training &amp; test sets Our first step is to split the data back into the original test and training sets. # Split the data back into a train set and a test set train &lt;- full[1:891,] test &lt;- full[892:1309,] 4.5.2 Building the model We then build our model using randomForest on the training set. # Set a random seed set.seed(754) # Build the model (note: not all possible variables are used) rf_model &lt;- randomForest(factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FsizeD + Child + Mother, data = train) # Show model error plot(rf_model, ylim=c(0,0.36)) legend(&#39;topright&#39;, colnames(rf_model$err.rate), col=1:3, fill=1:3) The black line shows the overall error rate which falls below 20%. The red and green lines show the error rate for ‘died’ and ‘survived’ respectively. We can see that right now we’re much more successful predicting death than we are survival. What does that say about me, I wonder? 4.5.3 Variable importance Let’s look at relative variable importance by plotting the mean decrease in Gini calculated across all trees. # Get importance importance &lt;- importance(rf_model) varImportance &lt;- data.frame(Variables = row.names(importance), Importance = round(importance[ ,&#39;MeanDecreaseGini&#39;],2)) # Create a rank variable based on importance rankImportance &lt;- varImportance %&gt;% mutate(Rank = paste0(&#39;#&#39;,dense_rank(desc(Importance)))) # Use ggplot2 to visualize the relative importance of variables ggplot(rankImportance, aes(x = reorder(Variables, Importance), y = Importance, fill = Importance)) + geom_bar(stat=&#39;identity&#39;) + geom_text(aes(x = Variables, y = 0.5, label = Rank), hjust=0, vjust=0.55, size = 4, colour = &#39;red&#39;) + labs(x = &#39;Variables&#39;) + coord_flip() + theme_few() Whoa, glad we made our title variable! It has the highest relative importance out of all of our predictor variables. I think I’m most surprised to see that passenger class fell to #5, but maybe that’s just bias coming from watching the movie Titanic too many times as a kid. 4.5.4 Prediction! We’re ready for the final step — making our prediction! When we finish here, we could iterate through the preceding steps making tweaks as we go or fit the data using different models or use different combinations of variables to achieve better predictions. But this is a good starting (and stopping) point for me now. # Predict using the test set prediction &lt;- predict(rf_model, test) # Save the solution to a dataframe with two columns: PassengerId and Survived (prediction) solution &lt;- data.frame(PassengerID = test$PassengerId, Survived = prediction) # Write the solution to file write.csv(solution, file = &#39;rf_mod_Solution.csv&#39;, row.names = F) "]
]
